{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNDcsiLY+KpJpyf8Js7KvkS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoheilBadri2000/DataScience2/blob/main/30.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "ze7mKjrVIYJV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jouvucmvHrPS",
        "outputId": "9ee80086-fe16-4d81-dc09-923149cb5311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-26 19:35:54--  https://raw.githubusercontent.com/amoudgl/short-jokes-dataset/master/data/reddit-cleanjokes.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 141847 (139K) [text/plain]\n",
            "Saving to: ‘reddit-cleanjokes.csv’\n",
            "\n",
            "\rreddit-cleanjokes.c   0%[                    ]       0  --.-KB/s               \rreddit-cleanjokes.c 100%[===================>] 138.52K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-26 19:35:55 (17.6 MB/s) - ‘reddit-cleanjokes.csv’ saved [141847/141847]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/amoudgl/short-jokes-dataset/master/data/reddit-cleanjokes.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "import pandas as pd\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "mVaV4oPfIqwI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "      def __init__(self, dataset):\n",
        "        super(Model, self).__init__()\n",
        "        self.lstm_size = 128\n",
        "        self.embedding_dim = 128\n",
        "        self.num_layers = 3\n",
        "\n",
        "        n_vocab = len(dataset.uniq_words)\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "\n",
        "        dropout_value = 0.2 if self.num_layers > 1 else 0\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.lstm_size,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=dropout_value,\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
        "\n",
        "      #   self.init_weights()\n",
        "\n",
        "      # def init_weights(self):\n",
        "      #     # Initialize embedding and linear layers\n",
        "      #     init.xavier_uniform_(self.embedding.weight)\n",
        "      #     init.kaiming_uniform_(self.fc.weight, nonlinearity='relu')\n",
        "\n",
        "      #     # Initialize LSTM weights\n",
        "      #     for name, param in self.lstm.named_parameters():\n",
        "      #         if 'weight_ih' in name:\n",
        "      #             init.xavier_uniform_(param.data)\n",
        "      #         elif 'weight_hh' in name:\n",
        "      #             init.orthogonal_(param.data)\n",
        "      #         elif 'bias' in name:\n",
        "      #             param.data.fill_(0)\n",
        "\n",
        "\n",
        "      def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.fc(output)\n",
        "        return logits, state\n",
        "\n",
        "      # Initialize weights\n",
        "\n",
        "\n",
        "      def init_state(self, sequence_length):\n",
        "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
        "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))"
      ],
      "metadata": {
        "id": "PYGIr2bQJj1y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        args,\n",
        "    ):\n",
        "        self.args = args\n",
        "        self.words = self.load_words()\n",
        "        self.uniq_words = self.get_uniq_words()\n",
        "\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
        "\n",
        "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "\n",
        "    def load_words(self):\n",
        "        train_df = pd.read_csv('reddit-cleanjokes.csv')\n",
        "        jokes = train_df['Joke'].tolist()\n",
        "        text = ' <eos> '.join(jokes)\n",
        "        return text.split(' ')\n",
        "\n",
        "    def get_uniq_words(self):\n",
        "        word_counts = Counter(self.words)\n",
        "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words_indexes) - self.args.sequence_length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            torch.tensor(self.words_indexes[index:index+self.args.sequence_length], dtype=torch.int64),\n",
        "            torch.tensor(self.words_indexes[index+1:index+self.args.sequence_length+1], dtype=torch.int64),\n",
        "        )\n"
      ],
      "metadata": {
        "id": "33xQ6CD-tkk7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, model, args):\n",
        "  model.train()\n",
        "  dataloader = DataLoader(dataset, batch_size=args.batch_size)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  for epoch in range(args.max_epochs):\n",
        "    state_h, state_c = model.init_state(args.sequence_length)\n",
        "\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "      loss = criterion(y_pred.transpose(1, 2), y)\n",
        "\n",
        "      state_h = state_h.detach()\n",
        "      state_c = state_c.detach()\n",
        "\n",
        "      loss.backward()\n",
        "      clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "      optimizer.step()\n",
        "\n",
        "      if batch % 100 == 0: # Adjust the frequency of Logging as needed\n",
        "        print({\"epoch\": epoch, \"batch\": batch, \"loss\": loss.item()})\n",
        "      if epoch % 10 == 0: # savethe model every 10 epochs\n",
        "        torch.save(model.state_dict(), f\"/content/model_epoch_{epoch}.pth\")"
      ],
      "metadata": {
        "id": "RthFSXZwdiLn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(dataset, model, text, next_words=100, temperature=1.0):\n",
        "  model.eval()\n",
        "\n",
        "  words = text.split(\" \")\n",
        "  state_h, state_c = model.init_state(len(words))\n",
        "\n",
        "  for i in range(0, next_words):\n",
        "    x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
        "    # x = x.to(model.device)\n",
        "    y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "    last_word_logits = y_pred[0][-1]\n",
        "    p = nn.functional.softmax(last_word_logits / temperature, dim=0).detach().numpy()\n",
        "    word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "    words.append(dataset.index_to_word[word_index])\n",
        "\n",
        "  return words"
      ],
      "metadata": {
        "id": "7odOnMoWmQiW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "  max_epochs = 10\n",
        "  batch_size = 256\n",
        "  sequence_length = 4\n",
        "\n",
        "args = Args()"
      ],
      "metadata": {
        "id": "Da3U7iv7slzV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset(args)\n",
        "model = Model(dataset)\n",
        "\n",
        "train(dataset, model, args)"
      ],
      "metadata": {
        "id": "jWx_vo3Ds2vu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f82302b-5e1b-455a-b7dd-4786c5633e2c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 0, 'batch': 0, 'loss': 8.843782424926758}\n",
            "{'epoch': 1, 'batch': 0, 'loss': 6.943517208099365}\n",
            "{'epoch': 2, 'batch': 0, 'loss': 6.881825923919678}\n",
            "{'epoch': 3, 'batch': 0, 'loss': 6.77602481842041}\n",
            "{'epoch': 4, 'batch': 0, 'loss': 6.613386631011963}\n",
            "{'epoch': 5, 'batch': 0, 'loss': 6.435757160186768}\n",
            "{'epoch': 6, 'batch': 0, 'loss': 6.272709369659424}\n",
            "{'epoch': 7, 'batch': 0, 'loss': 6.091189384460449}\n",
            "{'epoch': 8, 'batch': 0, 'loss': 5.914564609527588}\n",
            "{'epoch': 9, 'batch': 0, 'loss': 5.818454742431641}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Why did the children cross the road?\"\n",
        "generated_words = predict(dataset, model, text=prompt, next_words=50)\n",
        "\n",
        "# Combine the prompt and the generated words\n",
        "full_text = prompt + \" \" + \" \".join(generated_words[len(prompt.split()):])\n",
        "\n",
        "# Post-process for capitalization and proper spacing after punctuation\n",
        "processed_text = \" \".join([word.capitalize() if i==0 or full_text[i-2] in \".!?\"\n",
        "                          else word for i, word in enumerate(full_text.split())])\n",
        "\n",
        "print(processed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1o8NQ64i3HV",
        "outputId": "595c1b9e-3a63-4e2f-ad53-0b3ae93ad5e3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the children cross the road? magic name at the con-artist meet who up... internal Denim nosy? Me quack! <eos> What to hear you call the girl ...are dressed To it's with the cheapest moon? <eos> What do why kind the dune say on she Circle? under but he'd the Elementary joke There give with a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eKFOhrLe8erD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}